\pdfobjcompresslevel=0
\documentclass[fleqn,10pt]{wlscirep}
% \usepackage[modulo,switch]{lineno}
\usepackage{lineno}
% \modulolinenumbers[1]


\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{csvsimple}
\usepackage{booktabs}
% \usepackage{csquotes}


% for cross reference
\usepackage{xr-hyper}
% \usepackage{xr}
\usepackage[format=plain]{caption}

\makeatletter
\newcommand*{\addFileDependency}[1]{
    \typeout{(#1)}
    \@addtofilelist{#1}
    \IfFileExists{#1}{}{\typeout{No file #1.}}
}\makeatother
% link to supplementary tex
\newcommand*{\myexternaldocument}[1]{%
\externaldocument{#1}%
\addFileDependency{#1.tex}%
\addFileDependency{#1.aux}%
}
\myexternaldocument{suppl}




\title{MetaTCR: A Framework for Analyzing Batch Effects in TCR Repertoire Datasets}

\author[1]{Miaozhe Huo}
\author[1]{Yuepeng Jiang}
\author[1]{Yiping Zou}
\author[2]{Mengyao Wang}
\author[3]{Wei Zhang}
\author[1,*]{Shuai Cheng Li}
\affil[1]{Department of Computer Science, City University of Hong Kong, Hong Kong, China}
\affil[2]{Department xxxxx}
\affil[3]{Department xxxxx}

\affil[*]{shuaicli@cityu.edu.hk} 

% \keywords{Keyword1, Keyword2, Keyword3}

\begin{abstract}
The analysis of T-cell Receptor (TCR) Repertoires is fundamental to computational immunology. However, its potential is frequently compromised by batch effects, non-biological variations from technical sources that undermine the robustness and generalizability of analytical models. To address this challenge, we introduce MetaTCR, a framework designed to quantify and correct these distortions systematically. MetaTCR achieves this by clustering TCR clonotypes into unified, reference-based groups and converting repertoires into standardized feature profiles, termed meta-vectors. Building on this representation, we systematically benchmarked several metrics for quantifying inter-dataset dissimilarity, including Jensen-Shannon Divergence, symmetrized cross-entropy, cosine distance, Maximum Mean Discrepancy, the k-Nearest Neighbor Batch Effect Test (kBET), and the local inverse Simpson's index. Our evaluation reveals a critical functional dichotomy where Jensen-Shannon Divergence excels in linearity for quantifying global divergence magnitudes, whereas kBET demonstrates superior discriminative power in detecting local distortions and subtle artifacts. Leveraging this high resolution, MetaTCR employs kBET to drive the unsupervised partitioning of datasets, which enables the identification of latent batch structures without prior labels. This precise diagnosis facilitates targeted correction, and we demonstrate that integrating these insights with the Covariance matching algorithm effectively harmonizes datasets, significantly improving the domain generalizability of predictive models. Crucially, in a case study on a gastric cancer dataset, we show that applying this correction pipeline substantially alters the inferred differential V gene usage, highlighting how batch effects can lead to spurious biological findings. MetaTCR provides a comprehensive solution to diagnose, quantify, and mitigate these critical issues.
\end{abstract}

\begin{document}

\flushbottom
\maketitle
\linenumbers

\thispagestyle{plain}


\section*{Introduction}

T-cell receptor (TCR) repertoire diversity is fundamental to the adaptive immune response, reflecting an individual's immune status through a diverse array of TCR sequences\cite{janeway1997immunobiology, folch2000human, wang2010high, dewitt2018human}. This diversity records an individual's immunological history and actively drives adaptive immune responses\cite{dewitt2018human, emerson2017}. Consequently, variations in the TCR repertoire are directly linked to an individual's susceptibility to various diseases, including cancer, autoimmune disorders, and infectious diseases\cite{han2016immune, chiou2021global, servaas2021longitudinal, simnica2021landscape, tcrsep}.

With the development of high-throughput sequencing (HTS) technologies, adaptive immune receptor repertoire sequencing (AIRR-seq) has emerged as a powerful method for in-depth analysis of the immune system\cite{georgiou2014promise}. By specifically capturing the Complementarity Determining Regions (CDRs) on TCRs, pivotal in determining TCR diversity and specificity, AIRR-seq offers detailed insights into individual T cell repertoire dynamics. These insights enable researchers to systematically analyze immune responses, deepen their understanding of immune mechanisms, and advance clinical applications, such as vaccine development and cancer biomarker identification\cite{han2016immune, tcrsep, tcrpeg, gaide2015common, singh2017emerging, teinet}.

However, comparing AIRR-seq data from different sources remains challenging due to prominent batch effects—variations that arise from non-biological sources rather than true biological differences\cite{truck2021biological, katayama2022machine, andreatta2021interpretation, leek2010tackling}. These effects manifest as distinct sub-groups within the data, driven by differences in experimental conditions such as dates, environments, or protocols\cite{scherer2009batch}. The origins of such batch effects are multifaceted, stemming from variability in biological sample collection, differences in laboratory protocols and equipment, and even the bioinformatics pipelines employed for data processing\cite{leek2010tackling, andreatta2021interpretation, truck2021biological, carlson2013using, lin2020dissecting}.

For example, during AIRR-seq library preparation, the Multiplex (MTPX) PCR approach, which depends on gene-specific primers, can overrepresent certain genes, thereby distorting the true V gene distribution\cite{truck2021biological, carlson2013using}. While techniques like 5\' RACE help mitigate primer bias, their performance can vary considerably with laboratory protocols, and they may underrepresent clones with low expression levels\cite{lin2020dissecting, barennes2021benchmarking, rettig2019comparison}. A recent systematic investigation has confirmed that fundamental methodological choices, such as the quality and quantity of the starting nucleic acid and the specific PCR amplification strategy, profoundly impact the richness and diversity of the resulting repertoire profiles\cite{mahdy2025quantifying}. In addition, during the sequencing phase, factors such as nucleic acid cross-contamination within a batch and inherent amplification biases from polymerases may selectively amplify certain sequences, further skewing the abundance of TCR clonotypes\cite{best2015computational, gcbias, mamedov2013preparing}. Even after sequencing, differences in data processing parameters and software can introduce additional algorithm-based biases\cite{gerritsen2016rtcr, mixcr}.

Compounding these technical challenges, the vast number of unique TCR sequences in each individual, estimated between $10^7$ and $10^8$ unique TCR$\beta$ sequences, far exceeds the capacity of current sequencing technologies, resulting in significant under-sampling\cite{arstila1999direct, folch2000human, robins2009comprehensive, robins2010overlap}. The combination of under-sampling and batch effects often results in biased data that obscures the true relationship between TCR signatures and clinical conditions. Consequently, computational models built on such data suffer from limited reliability and poor generalizability\cite{motifboost}, a classic problem of domain adaptation where models trained on one data distribution fail on another\cite{blitzer2007learning}. This often occurs because models engage in ``shortcut learning'', identifying spurious correlations tied to batch metadata rather than robust biological signals\cite{geirhos2020shortcut}. To navigate the immense diversity of TCRs, a promising direction is to transform raw sequences into standardized features. For instance, the recent work by Hu \textit{et al.} on Repertoire Functional Units demonstrated that clustering TCRs into quantifiable units could reveal a shared pattern of immune aging across multiple repertoires\cite{Hu2024TCRunit}. However, while such standardization lays a conceptual foundation, there remains no widely adopted framework that systematically integrates high-dimensional repertoire encodings with batch correction algorithms explicitly tailored for cross-study TCR analysis. A dedicated solution is needed to not only standardize data but also rigorously evaluate how different integration strategies impact the preservation of biological signals versus the removal of technical noise.

To fill this gap, we developed MetaTCR, an end-to-end computational framework designed to standardize disparate TCR repertoires and explicitly correct for batch effects to enable robust downstream analysis. MetaTCR first addresses the standardization challenge by constructing a population-scale ``Referenced TCR Space'' from a large reference database and then projecting individual repertoires into it, yielding a standardized meta-feature matrix. To mitigate technical variations within these meta-vectors, the framework incorporates and benchmarks a suite of established integration algorithms. We comprehensively evaluated the efficacy of the MetaTCR framework combined with different integration tools across diverse scenarios using both simulated and real-world datasets. These assessments specifically focused on the framework's capacity to eliminate technical noise while preserving intrinsic biological signatures, thereby enhancing the generalizability of machine learning models. Furthermore, we demonstrated the practical utility of MetaTCR through a comprehensive case study on gastric cancer. This application successfully validated the complete workflow: from repertoire encoding and the identification of intra-dataset batch effects to effective batch correction and the subsequent re-analysis of V gene usage associations within the corrected landscape. Collectively, MetaTCR provides a robust, population-based solution for merging and analyzing TCR repertoire data, paving the way for more accurate and reproducible immunological discoveries.


\section*{Results}

\subsection*{Pervasive batch effects confound TCR repertoire analyses}

\input{sections/figure1}

Our multifaceted analysis reveals that different TCR repertoire datasets exhibit significant, systemic discrepancies in repertoire characteristics, underscoring the pervasive influence of batch effects. To systematically quantify these inconsistencies, we first compared repertoire-wide statistical features across multiple healthy donor and melanoma patient cohorts (Supplemental Tabs.~\ref{stab:melanoma_datasets_summary} and~\ref{stab:healthy_cohorts_summary} ). 

We observed that datasets profiling the same clinical condition exhibit distinct distributional characteristics at multiple levels of abstraction. First, at the gene-usage level, hierarchical clustering of V-gene usage demonstrates that repertoires from melanoma patients group primarily by their source dataset rather than by any shared biological condition (Fig.~\ref{fig:fig1}a). Complementing this, we analyzed the dataset feature using k-mer motif composition on CDR3 sequences. Principal Component Analysis (PCA) of these k-mer distributions revealed that repertoires form distinct clusters corresponding to their study of origin (Fig.~\ref{fig:fig1}b; Supplementary Figs.~\ref{sfig:healthy_cohorts_comparison}B and ~\ref{sfig:melanoma_cohorts_comparison}B), indicating that batch effects significantly skew the fundamental sequence composition. In parallel, we assessed the diversity of these repertoires (Supplementary  Method~\ref{smethod:shannon_stats}). An analysis of Shannon diversity revealed statistically significant differences in the mean diversity among cohorts that, in theory, should be comparable (Kruskal-Wallis test, $p < 0.0001$ for both healthy and melanoma super-groups; Supplementary Fig.~\ref{sfig:healthy_cohorts_comparison}A and ~\ref{sfig:melanoma_cohorts_comparison}A). For instance, within the melanoma group, post-hoc analysis identified that the Weber2018 cohort differed significantly from all other datasets profiling the same disease (Dunn's test, $p < 0.001$). This demonstrates that even a global statistical measure like diversity is heavily skewed by the dataset's origin.

These findings, based on abstract statistical features, are consistent with and extend observations at the direct clonotype level. We investigated clonotype sharing in three melanoma cohorts: Huuhtanen2022 ($n=17$), Robert2014 ($n=21$), and Weber2018 ($n=25$) (Supplemental Tab.~\ref{stab:melanoma_datasets_summary}). The analysis revealed that the fraction of shared clonotypes between randomly selected individuals within the same study was significantly higher (independent $t$-test, $p \leq 0.0001$) than the fraction observed between different studies (Fig.~\ref{fig:fig1}c), suggesting that so-called ``common TCRs'' often reflect inherent dataset-specific biases. To validate the universality of this bias, we expanded our analysis to seven datasets from diverse sources (Supplementary  Method~\ref{smethod:cross_dataset_shared_cdr3}, Supplementary Tab.~\ref{stab:healthy_cohorts_summary}). We specifically compared the overlap of shared CDR3 clonotypes in two scenarios: (1) between distinct clinical groups (e.g., Healthy vs. Patient) within the same dataset, and (2) between cohorts with the same clinical label (e.g., Healthy vs. Healthy) across different datasets. This broader comparison confirmed that the degree of clonotype sharing is consistently and markedly higher internally (within datasets) compared to externally (between datasets) (Fig.~\ref{fig:fig1}d), underscoring how technical boundaries can mask genuine biological signals.

These distributional inconsistencies have profound implications for machine learning models, which are highly susceptible to learning spurious, batch-specific features. We demonstrate this vulnerability through two case studies. First, we evaluated the generalization performance of a pre-trained classifier, DeepCAT, by validating it against different healthy negative controls. The model's performance was highly variable and unreliable, with AUC scores ranging from 0.1210 to 0.9317 (Fig.~\ref{fig:fig1}e). This drastic performance shift is directly explained by the technical divergence level of the negative set relative to the training data (Supplementary Tab.~\ref{stab:deepcat}). For instance, the model achieved a near-perfect AUC of 0.9317 when distinguishing between different experimental batches from the same lab, indicating it successfully learned batch-specific artifacts. Conversely, its performance collapsed to an AUC below 0.5 when tested against datasets from a different study or platform, demonstrating a catastrophic failure in generalization due to domain shift.

Second, to directly test for shortcut learning effect\cite{geirhos2020shortcut}, we trained a DeepTCR model on a semi-synthetic dataset where the biological label (simulated EBV infection) was deliberately confounded with a known batch difference. Despite achieving a near-perfect classification AUC of 0.97, the model largely failed to identify the ground-truth EBV-specific TCRs. Instead, it learned to distinguish the batch-specific signatures of the two cohorts (Fig.~\ref{fig:fig1}f, g; Supplementary Result \ref{sresult:ebv_analysis}). These experiments starkly illustrate how batch effects can lead models to identify false biomarkers. Conceptually, this failure occurs because the model, instead of learning the true biological `class boundary' that separates conditions, mistakenly learns the spurious `batch boundary' created by technical artifacts between datasets (Fig.~\ref{fig:fig1}h).


To formalize these observations, we model the observed repertoire \(\widehat{X}\) as:
\[
\widehat{X} = S\big(\mathcal{D}_{\mathrm{true}}\big) + B\big(\mathcal{D}_{\mathrm{true}}, \text{batch}\big) + \varepsilon,
\]

where \(S(\cdot)\) represents the true biological signal, \(B(\cdot)\) denotes the systematic bias induced by batch effects, and \(\varepsilon\) captures random sampling and technical noise. The repertoire we observe is merely a limited and biased subsample of an individual's full, true diversity, which itself is a fraction of the potential TCR universe (Fig.~\ref{fig:fig1}i). This fundamental challenge underscores the urgent need for a standardized profiling approach that can mitigate these confounding effects and enable the development of robust, generalizable models.


\subsection*{MetaTCR framework encodes standardized repertoire profiling}

\input{sections/figure2}

In response to the challenges of repertoire sparsity and technical noise described above, we developed the MetaTCR framework. The central hypothesis of this work is that the vast and complex TCR landscape can be organized into a finite set of ``functional clusters'' where TCRs share structural and functional properties captured by sequence embeddings\cite{TCR2vec}. By projecting individual repertoires onto this standardized reference space, MetaTCR creates a feature representation that is robust to undersampling and facilitates large-scale integration (Fig.~\ref{fig:fig2}a).

To establish this reference space, we integrated AIRR-seq data from 32 distinct datasets, encompassing 5,373 repertoires and over 5.1 million unique TCR$\beta$ clonotypes (defined by CDR3-V-J combinations). This curated database, denoted as $\text{TCR}_{\text{ref}}$, serves as the structural foundation for the framework. Detailed curation and preprocessing procedures are provided in the Methods.

A critical design choice in MetaTCR is the granularity of the reference clusters. Through a multi-objective evaluation across a range of cluster counts ($k$ ranging from 8 to 1024), we determined that $k=96$ represents an optimal balance between structural coherence and biological relevance. Specifically, $k=96$ maximized internal clustering quality metrics while maintaining high mean epitope purity and a significant correlation between structural and antigenic distances (Supplementary Fig.~\ref{sfig:select_bestK} and \ref{sfig:antigen_specificity}). Furthermore, this partition consistently yielded high performance in downstream classification tasks—achieving AUC scores of 0.8064 for CMV status and 0.9850 for SLE—confirming that these 96 clusters represent stable, intrinsic functional units rather than stochastic artifacts (Supplementary Fig.~\ref{sfig:k_classification_benchmark} and \ref{sfig:robustness_k96}).

This framework transforms each repertoire into a meta-vector, a holistic representation capturing two complementary immune dimensions: an \textit{abundance profile} (summed clonal frequencies per cluster) reflecting clonal expansion, and a \textit{richness profile} (unique clonotype counts per cluster) reflecting diversity. To account for rare or condition-specific TCRs that may fall outside this static reference, MetaTCR also incorporates a data-driven module to identify ``novel'' TCRs based on their structural distance from established centroids, ensuring that private or emerging immune signatures are not overlooked (see Methods and Supplementary Results~\ref{sresult:novel_tcr_analysis}).


\subsection*{Standardized meta-vector profiling captures individual signatures while revealing inter-study technical variation}
\input{sections/figure3}

Having constructed the MetaTCR framework, we next evaluated its utility as a standardized profiling tool. The goal was twofold: first, to validate that the meta-vector retains robust, individual-specific biological signatures within controlled settings, and second, to demonstrate that this standardized representation effectively exposes the dominant landscape of technical variation across diverse TCR studies.

We began by assessing the meta-vector's ability to generate a stable, personal immune signature where technical batch effects were minimal. We analyzed datasets where multiple samples were taken from the same individuals over time, sequenced via a uniform protocol. In the Sherwood2015 dataset\cite{sherwood2015}, meta-vectors from three healthy donors formed distinct, individual-specific clusters in a UMAP projection (Fig. \ref{fig:fig3}b), proving resilient to variations from different sampling time points. This stability is visually corroborated by hierarchical clustering of the functional cluster abundance profiles, which shows that samples from the same individual maintain consistent usage patterns over time, with minimal dynamic variation compared to the differences between individuals (Supplementary Fig.~\ref{sfig:sherwood_heatmap}). We further quantified this observation by computing the pairwise Jensen-Shannon Divergence (JSD) between all TCR repertoire samples (see Supplementary Method~\ref{smethod:metavec_signature_validation}). The resulting JSD heatmap (Supplementary Fig.~\ref{sfig:metavec_signature_validation}) provides strong quantitative validation, demonstrating extremely high intra-individual similarity (low JSD) across all time points and cell types, and high inter-individual dissimilarity (high JSD). This is consistent with the findings from Jiang \textit{et al.}~\cite{tcrsep} and confirms the meta-vector's ability to capture a signature with high stability and specificity. 

Similarly, in the Snyder2017 dataset involving cancer patients, we observed that repertoires clustered strongly by individual patient (Fig. \ref{fig:fig3}c, left). Notably, when the same embedding was colored by clinical response status, no clear separation was observed (Fig. \ref{fig:fig3}c, right), indicating that the inherent inter-individual heterogeneity constitutes a more dominant source of variation than the clinical signals in this unsupervised space. These results establish that the meta-vector effectively captures a stable, individual-specific signature, confirming its utility as a biological profiling tool while highlighting the challenge of extracting subtle clinical signals from a highly personalized immune background.

To rigorously quantify the sensitivity of the meta-vector to technical noise in a controlled setting with ground truth labels, we analyzed the Genolet2023 dataset\cite{genolet2023tcr}, which contains healthy murine samples processed under varying conditions (Supplementary Method~\ref{smethod:Genolet_metavec}). By comparing the standardized abundance profiles of the meta-vectors, we observed exceptional consistency among biological replicates, yielding Spearman correlations ($r$) exceeding 0.98. Our framework proved highly sensitive to technical deviations: correlations dropped significantly when comparing samples across experimental batches ($r < 0.60$) and further deteriorated across sequencing platforms ($r < 0.50$) (Supplementary Fig.~\ref{sfig:biological_rep_comparison_scatter_plots}). This analysis confirms that while the meta-vector creates a high-fidelity biological fingerprint for identical samples, it simultaneously encodes the specific footprint of the technical generation process.

Having confirmed the meta-vector's robustness in individual profiling, we next investigated the sources of variation across the dataset landscape. We analyzed a curated set of 20 PBMC cohorts (Supplementary Tab.~\ref{stab:all_pbmc_datasets_summary}), and their UMAP projection revealed a clear stratification where repertoires clustered primarily by study of origin (Fig. \ref{fig:fig3}d). When annotated by sequencing platform and processing pipeline, these clusters aligned with technical origins (Fig. \ref{fig:fig3}e and Supplementary Tab.~\ref{stab:study_platforms_pipelines}), indicating that platform differences and analytical workflows are the primary drivers of the observed inter-dataset gaps.

To further isolate the effect of technical variables from biological ones, we repeated this analysis on biologically homogeneous subsets. When analyzing only healthy donors from six different studies (Supplementary Tab.~\ref{stab:healthy_cohorts_summary}) or only melanoma patients from multiple studies, the repertoires still segregated by their source dataset rather than by their shared health status (Figs. \ref{fig:fig3}f, \ref{fig:fig3}g).

These results demonstrate that the meta-vector, by providing a standardized reference space, enables the measurement of the landscape of technical variation. This confirms that dataset-specific batch effects are a dominant source of inter-study differences in large-scale repertoire data.

\subsection*{Establishing robust metrics for quantifying TCR repertoire dataset dissimilarity}
\input{sections/figure4}

To distinguish technical artifacts from genuine biological signals within the standardized MetaTCR space, we benchmarked six candidate metrics, including the k-nearest neighbor batch effect test (kBET), maximum mean discrepancy (MMD), Jensen-Shannon divergence (JSD), symmetrized cross-entropy (CE), cosine distance, and local inverse Simpson’s index (iLISI). These tools were evaluated across the dimensions of sensitivity, stability, and batch effect discriminative power (Fig.~\ref{fig:fig4}a).

Sensitivity analysis revealed that JSD is the most effective tool for quantifying the magnitude of batch effects. Under simulated conditions mirroring realistic technical noise (Supplementary Fig.~\ref{sfig:biological_rep_comparison_distribution}), JSD demonstrated the strongest linear correlation with divergence levels and yielded an average Spearman correlation of 0.9556 (Fig.~\ref{fig:fig4}b, Supplementary Fig.~\ref{sfig:simulation_metrics_linearity}). Although kBET effectively detected the presence of bias, its scores did not scale linearly with batch intensity, as indicated by an average Spearman correlation of 0.8257. This finding suggests that JSD is better suited as a linear measure for the absolute magnitude of divergence.

Assessments of stability and discriminative power further identified kBET as a superior detector for technical artifacts. Stability profiling showed that both Cross-Entropy and kBET remained exceptionally consistent across varying sample sizes and random iterations, achieving stability scores near 1.00 (Fig.~\ref{fig:fig4}c). Conversely, iLISI proved sensitive to cohort imbalance, exhibiting increased variance when comparing datasets of differing sizes. In real-world discrimination scenarios, kBET and MMD outperformed other metrics in identifying subtle artifacts (Fig.~\ref{fig:fig4}d), with kBET achieving an AUC of 0.9648 in challenging same-platform comparisons and a perfect AUC of 1.0000 across different platforms (Supplementary Fig.~\ref{sfig:multi_batch_classifier}).

Integrating these results, we identified a functional trade-off between global measurement and local detection (Fig.~\ref{fig:fig4}e). While JSD is optimal for linearly describing global divergence, kBET is the most sensitive detector for identifying local distortions and artifacts within the embedding space. Given that batch integration relies on the optimization of local mixing, we prioritized kBET as the primary objective function for the MetaTCR framework.



\subsection*{Investigation of integration algorithms to mitigate batch effects and enhance model generalizability}

\input{sections/figure5}

With robust metrics established to quantify repertoire dissimilarity, we next addressed the challenge of correcting for these technical artifacts. A key advantage of the MetaTCR framework is that it transforms variable-length repertoire data into fixed-length meta-vectors, enabling the adaptation of powerful integration algorithms from single-cell transcriptomics. We evaluated Covariance matching, MNN, Scanorama, and Harmony using kBET as our primary evaluation tool (Methods), as our previous analysis identified it as the most effective detector for identifying the presence of artifacts within the MetaTCR embedding space.

We first examined the trade-off between noise removal and signal retention using our repertoire archetypes simulation (Methods). In this controlled setting, we generated six distinct biological profiles (archetypes) and deliberately confounded them with batch effects to test if algorithms could remove technical variance without erasing biological structure (Methods; Fig.~\ref{fig:fig5}a). For the baseline without integration, strong batch effects were evident, characterized by a kBET score of 1.000 and a Bio-Silhouette score (the silhouette coefficient computed using biological archetype labels) of 0.0663. While MNN and Scanorama failed to reduce the kBET score below the simulation-specific threshold of 0.9918, both Covariance matching and Harmony successfully mitigated the batch effect. However, they exhibited distinct behaviors regarding biological preservation. Covariance matching aggressively mixed the batches to a kBET of 0.7234 but compromised the cluster structure, resulting in a negative Bio-Silhouette score of -0.0188. In contrast, Harmony achieved an optimal balance; it successfully passed the batch correction threshold with a kBET of 0.9828 while retaining the highest biological fidelity among corrected methods (Bio-Silhouette = 0.0698), effectively preserving the distinct functional archetypes.

To validate these findings in a real-world context, we applied the algorithms to a composite dataset of healthy donor repertoires and a cohort of melanoma patients (Fig.~\ref{fig:fig5}b). Before integration, the healthy cohort exhibited severe study-specific stratification, with a kBET score of 0.9834, far exceeding the batch effect detection threshold of 0.8272. In this highly heterogeneous real-world setting, Covariance matching emerged as the most robust method. It was the only algorithm to successfully reduce the kBET score to 0.4283, falling well below the strict rejection threshold and indicating a comprehensive removal of study-specific artifacts. While Harmony visually improved alignment, it failed to satisfy the strict kBET criterion with a score of 0.9561, suggesting residual technical variance. Similar trends were observed in the melanoma cohort, where Covariance matching again achieved the lowest kBET score compared to the baseline without integration (Supplementary Fig.~\ref{sfig:melanoma_integration}; Supplementary Tab.~\ref{stab:real_world_integration_metrics}).

Finally, to evaluate the practical utility of batch correction, we assessed model generalizability on a CMV serostatus classification task using a rigorous cross-study transfer scenario (Methods). Models were trained on the Emerson2017 dataset and tested on the independent Huth2019 dataset. The impact of batch effects was clearly evident in the initial comparisons. The internal validation performance on the source dataset (using 5-fold cross-validation) indicated strong predictive potential with a mean AUC of 0.7731, with the Support Vector Classifier (SVC) WITH RBF kernel reaching an AUC of 0.8273. However, performance significantly degraded when testing on data without integration, where the mean AUC fell to 0.4953. For the SVC model, the cross-study AUC dropped to 0.5208, a result equivalent to random guessing. 

Integration algorithms showed varying degrees of success in restoring predictive power (Supplementary Tab.~\ref{stab:integration_performance}). As shown in Figs.~\ref{fig:fig5}c and d, Covariance matching emerged as the most robust method, achieving a mean AUC of 0.6961 across all classifiers and restoring the SVC performance to 0.7361. This represents a substantial recovery of biological signal, yielding an average improvement of 0.2008 over the unintegrated control ($\Delta$AUC vs. Control). Notably, this gain reached 0.2153 for the SVC model, significantly narrowing the performance gap relative to the internal validation baseline. In contrast, other methods, such as Harmony and Scanorama, failed to provide significant gains over the unintegrated baseline in this supervised task.

Taken together, these results highlight Covariance matching as the most effective integration strategy for MetaTCR-encoded data. By achieving the lowest kBET scores and demonstrating superior recovery of predictive performance in transfer learning tasks, Covariance matching successfully eliminates technical artifacts without compromising the biological signals essential for predictive modeling.


\subsection*{Uncovering latent technical heterogeneity in unannotated datasets}

Building on the benchmarking results, we extended the MetaTCR framework to address a critical challenge in public data usage: the detection of latent batch effects in datasets lacking experimental metadata. We developed an iterative optimization algorithm that leverages the sensitivity of the kBET metric to partition a dataset into two subsets (Methods). This approach aims to identify potential subgroups characterized by significant technical heterogeneity, which might otherwise remain hidden (Fig.~\ref{fig:fig6}a). Effectively identifying such latent stratification serves as an early warning system, preventing researchers from attributing batch-induced variance to biological factors.

We applied this unsupervised segmentation to the Wang2022 gastric cancer dataset as a case study. The algorithm converged on a partition with a kBET score of 0.9756, surpassing our empirically derived dissimilarity threshold of 0.8722. This result indicates the presence of substantial, previously unannotated technical artifacts within the dataset. To determine the nature of this variation, we evaluated its alignment with biological and demographic labels. First, the concordance between our algorithmically derived partition and the tumor versus healthy clinical labels yielded an accuracy of only 0.51, indicating a near-random association. To rigorously exclude other potential confounders, we performed statistical independence tests between the identified batches and demographic and clinical diagnostic characteristics, including age, gender, diagnosis, and tumor stage, including age, gender, diagnosis, and tumor stage (Supplementary Methods~\ref{smethod:wang2022_batch_independence_analysis}). All statistical tests yielded p-values greater than 0.01, confirming that the batch assignments are independent of these non-technical factors (Supplementary Fig.~\ref{sfig:wang2022_batch_independence}). These results collectively demonstrate that the identified variation is orthogonal to biological conditions and likely stems from undocumented technical factors.

To independently validate that this partition represented a genuine, systematic difference in repertoire features rather than algorithmic noise, we trained a DeepTCR classifier to distinguish between the two latent batches identified by our algorithm (Methods; Fig.~\ref{fig:fig6}b). The model achieved a near-perfect Area Under the Curve (AUC) of 1.0. In stark contrast, when the classifier was trained on random splits of the same data, it failed to learn any discriminative features, yielding an average AUC of 0.49 $\pm$ 0.12 (Fig.~\ref{fig:fig6}c). This confirms that the batch structure identified by MetaTCR is a systematic feature of the sequence data. Furthermore, analyses of V and J gene co-occurrence frequencies revealed distinct patterns between the two latent batches (Supplementary Fig.~\ref{sfig:wang2022_gastricVJgene}), suggesting that these technical artifacts are pervasive enough to obscure genuine biological signals.


\subsection*{Correction of latent artifacts rectifies biological interpretation}

\input{sections/figure6}

The presence of such strong, latent batch effects poses a severe risk to downstream analysis, potentially leading to erroneous biological conclusions. To demonstrate the necessity of the MetaTCR workflow, we performed a comparative analysis of the Wang2022 dataset before and after applying Covariance matching -based batch correction, focusing on the differential usage of V genes between healthy donors and gastric cancer patients.

Initial visualizations of V gene usage distributions revealed that technical noise severely confounded the biological signal. As shown in Fig.~\ref{fig:fig6}e, the usage frequencies of specific V genes in the data before integration (left panel) exhibited high variance that masked the distinction between tumor (orange) and healthy (green) samples. However, after applying the Covariance matching correction (right panel), the variance within groups was reduced, and the true biological differences between the tumor and healthy cohorts became clearly distinguishable.

This correction substantially altered the identification of potential biomarkers. We compared the top upregulated and downregulated V genes based on their log-fold changes (LogFC) before and after correction. In the analysis using data without integration, the ranking of significant genes was dominated by technical noise (Fig.~\ref{fig:fig6}d, top panel). Following batch correction, the landscape shifted markedly: genes such as \textit{TRBV27} and \textit{TRBV30}, which were prominent in the raw analysis, lost their top-ranking status, while a new set of markers, including \textit{TRBV3-1} and \textit{TRBV6-3}, emerged as the most significant drivers of the biological difference (Fig.~\ref{fig:fig6}d, bottom panel).

Most importantly, the correction did not merely refine significance levels but in some cases reversed the direction of the estimated biological effect. As illustrated in the global analysis of effect sizes (Fig.~\ref{fig:fig6}f), we observed significant deviations in the LogFC values for the union of all differential V genes. For several genes, the sign of the LogFC flipped, meaning a gene that appeared downregulated in the raw data was found to be upregulated (or unchanged) after correcting for the latent batch effect. These findings underscore that without the rigorous detection and correction pipeline provided by MetaTCR, technical artifacts can drive spurious associations, leading to false positive discoveries and the misinterpretation of immune repertoire alterations in disease.

\section*{Discussion}

The pervasive influence of batch effects in TCR repertoire data has historically been a significant barrier to large-scale integrative analyses. In this study, we introduced MetaTCR to bridge this gap by transforming unordered sets of isolated TCR clonotypes into interpretable, fixed-dimensional meta-vectors. This quantitative interface seamlessly integrates with established batch correction algorithms, such as the covariance matching method. Our analyses demonstrate that without such rigorous correction, technical variability, manifesting in metrics ranging from V/J gene usage to k-mer profiles, can easily obscure genuine biological heterogeneity, rendering cross-study comparisons unreliable.

A central finding of our work is that the repertoire encoding strategy employed prior to integration dictates the success of domain adaptation. When benchmarked against alternative unsupervised representations, including sparse 3-mer counts, raw V/J gene usage, and GIANA-based embeddings (Supplementary Method~\ref{smethod:feature_definitions}), MetaTCR consistently demonstrated superior performance (Supplementary Fig.~\ref{sfig:feature_comparison}). Specifically, meta-vectors achieved the highest internal predictive potential (AUC 0.8319) and yielded the most substantial gains from Covariance matching, reaching a cross-study AUC of 0.7361. In contrast, simpler sequence-level descriptors struggled to preserve biological signals during integration. These results underscore that MetaTCR’s attention-based clustering captures high-order structural relationships that are uniquely amenable to batch correction, whereas lower-level features often conflate technical noise with biological signal.

% Beyond standardizing repertoires, the reference-based nature of MetaTCR offers granular insights into repertoire structure, particularly regarding ``novel TCRs'', defined as sequences distinct from predefined cluster centroids. Our analysis first highlights that the distribution of these outliers varies systematically across different melanoma datasets (Supplementary Fig.~\ref{sfig:novel_tcr_analysis}a), suggesting that technical batches can manifest as shifts in structural outliers. However, rather than being mere noise, these peripheral sequences also carry critical immunological information. In the Emerson2017 dataset, we found that the prevalence of novel TCRs within specific functional clusters is significantly associated with CMV serostatus (Supplementary Fig.~\ref{sfig:novel_tcr_analysis}b, Supplementary Tab.~\ref{stab:novel_tcr_diff_clusters}). This dual nature implies that while novel TCR density can serve as a sensitive quality control metric for detecting batch effects, it simultaneously captures genuine biological heterogeneity. Consequently, future iterations of the framework should move towards adaptive models that can dynamically ingest outliers to refine the reference landscape as new datasets become available.
A potential constraint of fixed-dimensional representations lies in the reliance on a static reference database, which theoretically risks overlooking dataset-specific TCR groups that are not present in the reference. To mitigate this limitation, we explored a strategy to accommodate these ``unseen'' sequences by systematically identifying them as ``novel TCRs'' (Supplementary Method~\ref{smethod:novel_tcr_definition}). These novel groups serve to supplement the reference-based features, effectively capturing the diversity that extends beyond pre-defined functional clusters. Our exploratory analysis confirms that these supplementary features are information-rich rather than random noise. On one hand, they reflect technical variability: we observed dataset-specific distributions of novel TCRs across four different melanoma cohorts (Supplementary Fig.~\ref{sfig:novel_tcr_analysis}a), indicating that batch effects permeate even these non-reference sequences. On the other hand, they preserve biological sensitivity: within the Emerson2017 cohort, specific novel clusters showed significant differential abundance between CMV-positive and CMV-negative individuals (Supplementary Fig.~\ref{sfig:novel_tcr_analysis}b, Supplementary Table~\ref{stab:novel_tcr_diff_clusters}). These results demonstrate that while a static reference provides a robust common ground, the framework has the potential to be extended with novel groups to account for dataset-specific diversity.

Regarding the scope of input data, paired $\alpha\beta$ chain information undoubtedly provides a more comprehensive resolution of epitope specificity compared to single-chain data\cite{ergo2}. To empirically validate the extensibility of our framework to this higher-dimensional modality, we conducted a proof-of-concept study using single-cell paired datasets (Supplementary Method~\ref{smethod:ab_paired_metatcr}, Supplementary Tab.~\ref{stab:sc_ab_datasets}). Initial exploratory analysis confirmed that these datasets possess distinct baseline characteristics, evidenced by significant shifts in Shannon entropy and amino acid k-mer distributions (Supplementary Fig.~\ref{sfig:paired_data_exploratory_analysis}). By projecting these repertoires into the paired reference space, MetaTCR effectively captured these variations. Applying the kBET metric—previously identified as the most robust indicator in our single-chain benchmarks—we demonstrated that the quantitative distances between independent studies significantly exceeded the intra-dataset noise floor (Supplementary Result~\ref{sresult:paired_evaluation}, Supplementary Fig.~\ref{sfig:paired_distance_heatmap}). This confirms that the framework allows for the rigorous detection of batch effects in paired data. However, a practical constraint remains: the vast majority of public large-scale cohorts are currently limited to bulk TCR$\beta$ sequencing, and paired datasets of sufficient size to build robust, universal references are still scarce. Consequently, while MetaTCR is purposefully designed to unlock the latent value within the massive existing bulk data landscape, our pilot validation confirms that the underlying embedding module possesses an extensible architecture, ready to be seamlessly upgraded as large-scale paired cohorts become the standard.

In conclusion, our findings establish MetaTCR as a robust solution for the diagnosis and mitigation of batch effects in TCR repertoire data. By enabling the rigorous quantification of both core repertoire features and structural outliers, MetaTCR lays the conceptual groundwork for the next generation of immune repertoire analysis, moving beyond static clustering toward adaptive, high-resolution modeling of immune diversity.


\section*{Methods}

\subsection*{Data acquisition and preprocessing of TCR repertoire data}

To ensure a wide range of sources for the TCR reference database and minimize potential biases, we curated 5,373 TCR repertoires originating from 32 distinct studies and batches. These data encompass various sequencing platforms, including ImmunoSEQ Assay, Illumina HiSeq, and BGISEQ 500, representing a broad spectrum of biological states from healthy individuals to patients with conditions such as melanoma and gastric cancer. 

A meticulous cleaning process was implemented to ensure high sequence quality. Entries with CDR3$\beta$ chain lengths shorter than 10 amino acids or with nucleotide sequences containing stop codons were discarded. Additionally, only amino acid sequences beginning with cysteine (C) and ending with phenylalanine (F) were retained. For each filtered repertoire, the most abundant clones, up to a maximum of 10,000, were selected for downstream analysis.

\subsection*{The MetaTCR framework}

\textbf{Development of TCR clonotype reference database.} After preprocessing, a random subset of 50 repertoires was selected from each dataset. From each repertoire, the 5,000 TCR sequences with the highest clone frequencies were extracted as representative TCR clonotypes. Duplicate sequences were removed, yielding a curated TCR reference database, denoted as \(\text{TCR}_{\text{ref}}\), which contains 5,174,021 unique clonotypes.

\textbf{Encoding TCR clonotypes.} Each TCR clonotype was defined by its CDR3 sequence and V/J segments. These components were concatenated and transformed into \(d\)-dimensional vectors using the TCR2vec model \cite{TCR2vec}, resulting in TCR embeddings with a shape of \(n \times d\). Here, \(n\) denotes the number of TCR clonotypes—either within the reference database or a single repertoire—and \(d = 120\) is the feature dimension of the TCR embedding.

\textbf{Two-stage clustering of the reference database.} The TCR reference database \(\text{TCR}_{\text{ref}}\) was transformed into a collection of embeddings, \(\text{TCR}_{\text{ref}}^{\text{emb}}\). These were first organized into \(j = 1024\) primary TCR clusters using the k-means algorithm (FAISS package, Euclidean distance) \cite{faiss}, yielding primary centroids \(\mathcal{C}^{(p)} = \{c_1^p, \ldots, c_{j}^p\}\). To group these into a smaller, more functionally relevant set, we applied spectral clustering using scikit-learn (version 1.1.3). The affinity matrix was constructed using a nearest-neighbor approach with the number of neighbors for each centroid set to 10. This process yielded the final functional TCR centroids, \(\mathcal{C}^{(F)} = \{c_1, \ldots, c_{k}\}\).

\textbf{Determination of the optimal number of functional clusters.} To determine the optimal number of clusters \(k\), we evaluated a range of candidate values from 8 to 1024 using three criteria. First, intrinsic cluster quality was assessed via the Within-Cluster Sum of Squares (WSS), Calinski-Harabasz Score, Silhouette Score, and an imbalance factor. Second, antigen specificity was evaluated using TCR-epitope pairing data from the McPAS database, calculating epitope purity and the correlation between embedding distances and antigen profile distances. Third, biological relevance was quantified by evaluating meta-vector performance in classification tasks (CMV status, SLE, and lung cancer). Integrating these results, \(k=96\) was identified as the optimal balance for preserving biological signals. This partition was further validated as a stable solution by re-running the clustering 50 times (Supplementary Fig.~\ref{sfig:robustness_k96}).

\textbf{Encoding repertoires into meta-vectors.} For each repertoire \(R_i\) containing \(n\) unique clonotypes, the embeddings \(R_i^{emb} \in \mathbb{R}^{n \times d}\) were assigned to their nearest functional centroids in \(\mathcal{C}^{(F)}\). Based on this assignment, we constructed two profiles: an \textbf{abundance profile} (\(\mathbf{a}_i\)), created by summing the frequencies of clones in each cluster followed by a \(\log(1+x)\) transformation; and a \textbf{richness profile} (\(\mathbf{d}_i\)), created by counting unique clonotypes per cluster and normalizing to proportions. The final TCR meta-vector \(\mathbf{R}_i^{\mathrm{meta}} \in \mathbb{R}^{2k}\) is the concatenation of these two profiles:
\[
\mathbf{R}_i^{\mathrm{meta}} = \begin{pmatrix} \mathbf{a}_i \\ \mathbf{d}_i \end{pmatrix}.
\]
For a dataset \(S\) containing \(m\) samples, the resulting TCR meta-matrix is defined as \(\mathbf{S}^{\mathrm{meta}} \in \mathbb{R}^{m \times 2k}\), providing a standardized representation of clonal expansion and diversity across all functional clusters.



\subsection*{Dimensionality reduction and visualization for repertoire profiling}

To visualize the relationships between TCR repertoires, we performed dimensionality reduction on their meta-vector representations using Uniform Manifold Approximation and Projection (UMAP)\cite{umap}. All UMAP embeddings were generated from the \(m \times 2k\) meta-matrix using the \textit{umap-learn} package in Python with a Euclidean distance metric. The parameters were adapted based on sample size: for UMAP analyses involving over 1,000 samples, we used $n_{\text{neighbors}}=30$ and $min_{\text{dist}}=0.5$; for smaller datasets, we used $n_{\text{neighbors}}=15$.

We conducted several analyses to investigate inter- and intra-dataset variation:
\begin{enumerate}
    \item \textbf{Global analysis of cross-study variation:} A global UMAP embedding was generated from a subset of the collected data. To minimize tissue-specific bias and ensure statistical robustness, we restricted this analysis to datasets derived exclusively from PBMCs and containing more than 20 samples. This resulted in a final set of 20 distinct studies. To prevent graphical bias from datasets with disproportionately large numbers of repertoires, studies containing more than 300 repertoires were randomly downsampled to 300. In the resulting visualization, data points were colored by their study of origin to assess dataset-level clustering and observe potential batch effects.
    
    \item \textbf{Analysis of biologically homogeneous cohorts:} To examine the relationship between repertoires with the same biological context but derived from different studies, we partitioned the data into two major cohorts: ``healthy donors'' and ``patients with melanoma''. UMAP was applied separately to the meta-vectors within each cohort to investigate whether repertoires would primarily cluster by their study of origin, which would indicate the presence of strong study-specific technical artifacts over shared biological signals.
    
    \item \textbf{Validation of meta-vector robustness and specificity:} To confirm that meta-vectors are robust to short-term intra-individual immune dynamics while remaining specific to inter-individual differences, we analyzed two longitudinal datasets. First, we utilized the Sherwood2015 dataset\cite{sherwood2015}, which contains TCR repertoires from both PBMCs and sorted memory T-cell populations, sampled from three healthy donors across eight distinct time points. The meta-vectors from this dataset were visualized with points colored by donor ID to assess inter-individual specificity. Second, we analyzed a cohort from the Snyder2017 dataset\cite{snyder2017contribution}, which profiles cancer patients undergoing immunotherapy. We selected 23 patients for whom at least three longitudinal PBMC samples were available, resulting in a total of 80 repertoires. These were visualized with points colored by either patient ID or treatment response labels to assess both individual specificity and biological state separation.  
\end{enumerate}

\subsection*{Quantification of batch dissimilarity}

To quantify the dissimilarity between two cohorts of repertoire meta-vectors, we employed several batch dissimilarity metrics. We evaluated the k-Nearest Neighbor Batch Effect Test (kBET)\cite{kbet}, which assesses local batch mixing; the local inverse Simpson's Index (iLISI)\cite{lisi}, which measures mixing in a density-aware local neighborhood; the Maximum Mean Discrepancy (MMD)\cite{mmd}, a kernel-based method that measures the distance between the overall distributions; and Jensen-Shannon Divergence (JSD), symmetrized cross-entropy, and cosine distance, which all quantify dissimilarity by averaging pairwise comparisons between individual repertoire profiles from the two cohorts. For all metrics, a higher value indicates greater batch dissimilarity or poorer mixing. Detailed formulations are provided in Supplementary Methods Section~\ref{smethod:metric_details}.

\subsection*{Benchmarking framework for batch dissimilarity metrics}

We established a benchmarking framework evaluating three critical properties: sensitivity to batch magnitude, stability against sampling variation, and real-world batch discriminative power. To account for negligible numerical differences, we implemented a ranking scheme with a 10\% tolerance threshold, assigning tied ranks to methods with comparable performance. 

\subsubsection*{Task 1: Metric Sensitivity Analysis}
To assess whether metrics could linearly reflect the magnitude of batch effects, we designed a simulation using real-world profiles as the source dataset. Building on our finding that a Gamma distribution can effectively model batch effects in the meta-vector space, we generated synthetic target datasets by applying controlled perturbations. We generated source-target pairs with graded levels of divergence through three controlled modes:
\begin{itemize}
    \item \textbf{Differential Cluster Proportion:} Varying the fraction of TCR functional clusters affected by the bias.
    \item \textbf{Differential Effect Magnitude:} Varying the intensity (Gamma shape parameter) of the batch effect applied to the clusters.
    \item \textbf{Dataset Admixture:} Using profiles from two distinct real-world datasets as foundations, we mixed source and target samples at varying ratios to construct graded source-target pairs.
\end{itemize}
Detailed simulation methodologies are provided in Supplementary Methods Section~\ref{smethod:task1_sensitivity}. Performance was quantified by the Spearman correlation between metric scores and the predefined divergence levels.

\subsubsection*{Task 2: Metric Stability Profiling}
To evaluate the stability of metrics against irrelevant technical variation, we measured the consistency of scores under constant distributional conditions. We adopted a fixed-reference sampling strategy: while the source dataset remained fixed, we iteratively sampled subsets from the target dataset to compute dissimilarity scores. This design ensures that any fluctuation in the metric arises solely from sampling stochasticity rather than changes in the underlying data distribution. 

We assessed stability in two contexts: subsampling stability (repeated random subsets of a fixed size) and sample size stability (systematically varying the total number of repertoires). To ensure a rigorous evaluation, these experiments were performed in both a cross-study setting (strong batch effect) and a within-study setting (weak batch effect). Stability was quantified using the Coefficient of Variation (CV), with the final stability score defined as $1 - \text{CV}$. Detailed procedures are described in Supplementary Methods Section~\ref{smethod:task2_stability}.

\subsubsection*{Task 3: Real-World Batch Discrimination}
To validate performance on empirical data, we designed a stratified binary classification framework using 150 TCR repertoire dataset pairs. These included data pairs from the same study (\textit{no batch} pairs, as the negative pairs), pairs from different studies using the same ImmuneSEQ platform, and pairs from different studies using different TCR sequencing platforms.

This design enabled us to assess metric performance across two distinct difficulty levels. The first, more challenging scenario evaluated the ability to distinguish \textit{no batch} pairs from \textit{same platform} pairs, testing sensitivity to subtle technical variations within a single technology. The second, less challenging scenario involved distinguishing \textit{no batch} pairs from \textit{different platform} pairs, testing the detection of strong batch effects driven by cross-platform divergence. We calculated the AUC for both classification tasks and quantified final performance as the average AUC, ensuring the metric's robustness across a broad spectrum of real-world conditions. Detailed procedures are provided in Supplementary Methods Section~\ref{smethod:task3_realworld}.

\subsection*{Algorithms for meta-vector integration}

To correct for batch effects in the meta-vector data, we benchmarked several established integration algorithms. A key requirement for our selection was that the method must produce a corrected data representation that preserves the original dimensionality of the meta-vectors, ensuring that all features remain interpretable post-integration. The selected methods included Covariance matching \cite{coral}, which aligns the covariance matrices of source and target datasets through a linear transformation; Mutual Nearest Neighbors (MNN), which identifies shared cell populations to compute a batch correction vector\cite{mnn}; Scanorama, which extends the principle of nearest-neighbor matching to efficiently ``stitch'' together multiple heterogeneous datasets\cite{scanorama}; and Harmony, an iterative method that projects samples into a shared embedding to promote batch mixing\cite{lisi}.

To ensure consistency across methods, we adapted the standard Harmony workflow, which typically involves a preliminary dimensionality reduction step via PCA. Our implementation bypasses this step, applying the integration algorithm directly to the complete meta-vector features. This modification ensures that the corrected data matrix retains the original feature dimensions, making its results directly comparable to those from Covariance matching, MNN, and Scanorama. The specific implementation details for each algorithm are provided in the Supplementary Methods (Supplementary Method~\ref{smethod:integration}).


\subsection*{Evaluation of data integration methods}

To evaluate the efficacy of integration algorithms, we extended our simulation framework to assess the trade-off between removing technical noise and preserving biological signals. Furthermore, we validated the most promising methods on real-world cohorts through biological retention and predictive modeling tasks.

\subsubsection*{Task 4: Retention of repertoire archetypes}

This task evaluated the ability of integration methods to preserve complex biological structures. We computationally defined six 'Repertoire Archetypes' by amplifying unique sets of functional clusters within distinct sample groups. A strong, uniform batch effect was applied to half of the dataset. Performance was assessed both visually with UMAP and quantitatively with batch dissimilarity metrics to measure batch mixing and the preservation of the archetype structure. A successful integration must effectively mix batches while retaining the distinct biological clusters.

\subsubsection*{Task 5: Batch integration in real-world cohorts}
To validate integration in a realistic setting, we applied the methods to harmonize repertoires sharing identical biological labels across multiple independent studies. As these cohorts represent the same biological state, any separation is attributable to technical batch effects. We evaluated efficacy through visual inspection of UMAP embeddings and quantitative analysis using batch dissimilarity metrics. Integration was deemed successful if metric scores dropped below the optimal classification thresholds established in Task 3, indicating that residual batch effects were rendered statistically indistinguishable from biological variation.


\subsubsection*{Task 6: Enhancement of repertoire classification model generalizability}

To evaluate the impact of batch correction on model generalizability, we designed a prediction task for CMV serostatus using a diverse suite of classifiers. We employed a source-target transfer framework where models were trained on the Emerson2017 dataset ($n=760$) and tested on the independent Huth2019 dataset ($n=25$). Both datasets contained CMV-positive and healthy donor samples with no confounding technical variables between classes within each study. We compared the predictive performance, measured by the classification AUC, of models utilizing data processed by different integration methods against the control without integration. Additionally, we established a validation baseline by performing 5-fold cross-validation within the source dataset to approximate the ideal model performance in the absence of batch effects. To quantify the gap between actual transfer performance and the ideal baseline, we calculated the $\Delta$AUC for each method.

Detailed parameters for all simulation and real-world scenarios are provided in Supplementary Methods Section~\ref{smethod:benchmarking_integration}.


\subsection*{Unsupervised discovery of latent batches using iterative optimization}

To identify potential technical artifacts in datasets lacking explicit batch metadata, we developed an iterative optimization algorithm designed to segment samples into two maximally dissimilar groups, referred to as latent batches. The core of this method is an objective function based on the Jensen-Shannon Divergence (JSD), which provides a smooth optimization landscape where a higher divergence indicates a stronger separation between the two groups. Unlike methods that might optimize batch effect metrics directly, our algorithm iteratively refines the binary partition of the repertoire meta-vectors, \(\mathbf{R}_i^{\mathrm{meta}}\), to maximize this JSD score, while reserving the kBET metric for periodic model evaluation.

The process is initialized by generating a preliminary partition using Spectral Clustering. Subsequently, the algorithm iteratively refines this partition by attempting to swap samples between the two latent batches. To ensure efficiency, candidate samples for swapping are preferentially selected from the periphery of their respective clusters. A proposed swap is accepted if it increases the JSD between the groups. To escape local maxima, the algorithm incorporates a simulated annealing mechanism, allowing it to probabilistically accept swaps that temporarily decrease the JSD score. Throughout this optimization, the kBET metric is calculated at fixed intervals as a convergence benchmark; if the partition achieves a kBET score exceeding a predefined threshold, the optimization terminates early. This dual-metric approach ensures that the search is guided by the robust gradients of JSD while the final output is validated by the sensitivity of kBET. The pseudocode for this procedure is provided in Supplementary Section~\ref{smethod:alg:batch_seg}.

\subsection*{Sequence-level validation of latent batches using DeepTCR}

To verify that the latent batches identified by our algorithm on meta-vectors reflect systematic differences at the raw sequence level, we employed DeepTCR as an independent classifier. Let ${S}_{1}$ and ${S}_{2}$ denote the sets of repertoires assigned to the two latent batches. The union of these sets is denoted as ${S}_{total}$.

First, we trained a DeepTCR classifier to distinguish between repertoires in ${S}_{1}$ and ${S}_{2}$ using a binary classification setup. The model's performance was quantified using the Area Under the Curve (AUC) score via cross-validation. A high AUC indicates that the latent batches possess distinct sequence-level features.

As a negative control, ${S}_{total}$ was randomly partitioned into two subsets of equal size, ${S}_{A}$ and ${S}_{B}$. The DeepTCR classifier was then retrained to differentiate between these randomly generated subsets. The AUC scores derived from the latent batch classification (${S}_{1}$ vs. ${S}_{2}$) were compared against those from the random split classification (${S}_{A}$ vs. ${S}_{B}$). This comparison assesses whether the detected batch effect represents a learnable, systematic signal distinct from random variation.


\subsection*{Impact of batch correction on differential V gene usage analysis}

We utilized the Wang2022 dataset \cite{wang2022} to evaluate how correcting latent batch effects alters the interpretation of biological signals—specifically, the V gene usage differences between gastric cancer patients and healthy controls. 

First, we constructed a mapping between functional clusters derived from the complete set of TCR clonotypes and their corresponding V genes, yielding the set \( c^v = \{ c^v_1, c^v_2, \dots \} \). Using this mapping, each repertoire’s meta matrix \(\mathbf{R}_{i}^{\mathrm{meta}}\) was transformed into a normalized V gene usage profile, accounting for differences in sequencing depth.

Differential analysis was performed in two scenarios: on the original data (without integration) and on the data after applying Covariance matching -based batch correction to align the latent batches. In both scenarios, samples were stratified based on their clinical labels (Gastric Cancer vs. Healthy). A two-sample t-test was applied to each V gene to assess the significance of usage differences, with a significance threshold of \(p < 0.05\). The log-fold change (LFC) was computed as the logarithm of the ratio between the average V gene usage in tumor samples and that in healthy samples. Genes were ranked by LFC to identify the top upregulated and downregulated markers, allowing for a direct comparison of biological conclusions drawn before and after technical artifact removal.




\bibliography{sections/reference}

\section*{Data availability}
The TCR repertoire AIRR-seq data utilized in this study were sourced from public repositories, including the Gene Expression Omnibus (GEO) and the ImmuneACCESS database, as well as from previously published studies. A comprehensive description of all datasets, along with their accession numbers or original citations, is provided in Supplementary Tab. \ref{stab:all_pbmc_datasets_summary}. The constructed TCR reference database, processed meta-vectors, and other intermediate results generated during this analysis have been deposited in Zenodo and are accessible at \url{https://doi.org/10.5281/zenodo.18265157}.

\section*{Code availability}
The MetaTCR framework is implemented as an open-source Python package and is available at \url{https://github.com/deepomicslab/metatcr}. All scripts required to reproduce the experiments and analyses presented in this paper are hosted at \url{https://github.com/deepomicslab/metatcr-exp}.

\section*{Acknowledgements}

The authors would like to thank Jiaqi Luo of the Department of Computer Science at City University of Hong Kong. Their contributions to providing and processing part of the datasets and their active participation in our discussions were invaluable to the progress and outcome of this research.

\section*{Author contributions statement}

S.C.L. conceived and initiated this study. M.H. and Y.J. conducted the experiments and analyzed the results. M.H., Y.Z., W.Z., and M.W. collected and processed the datasets in this project. M.H. wrote the manuscript under the supervision of S.C.L.. All authors polished and reviewed the manuscript. 

\section*{Competing interests statement}

The authors declare no competing interests.


\end{document}